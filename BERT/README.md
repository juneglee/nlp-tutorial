# transformer : attention is all you need for pytorch

paper
- [Bidirectional Encoder Representations from Transformers ](https://arxiv.org/pdf/1810.04805.pdf)

reference
- https://github.com/google-research/bert